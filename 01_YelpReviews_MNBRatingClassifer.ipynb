{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Homework with Yelp reviews data\n",
    "\n",
    "##Introduction\n",
    "- This assignment uses a small subset of the data from Kaggle's Yelp Business Rating Prediction competition.\n",
    "**At the heart of any recommender system is an algorithm to predict ratings.  Contestants are asked to predict the usersâ€™ future ratings of businesses. Participants will create a model to predict the rating a user would assign to a business. Models will be graded on accuracy using the root mean squared error metric. See the Evaluation page for more details**\n",
    "\n",
    "**Description of the data**:\n",
    "1. *yelp.csv* contains the dataset. It is stored in the course repository (in the data directory), so there is no need to download anything from the Kaggle website.\n",
    "\n",
    "2. *Each observation (row)* in this dataset is a review of a particular business by a particular user.\n",
    "\n",
    "3.  The *stars column* is the number of stars (1 through 5) assigned by the reviewer to the business. (Higher stars is better.) In other words, it is the rating of the business by the person who wrote the review.\n",
    "\n",
    "4. The *text column* is the text of the review.\n",
    "\n",
    "5. The *cool column* is the number of \"cool\" votes this review received from other Yelp users. All reviews start with 0 \"cool\" votes, and there is no limit to how many \"cool\" votes a review can receive. In other words, it is a rating of the review itself, not a rating of the business.\n",
    "\n",
    "6. The *useful and funny* columns are similar to the cool column.\n",
    "\n",
    "**Goal**: Predict the star rating of a review using only the review text. (We will not be using the cool, funny, or useful columns.)\n",
    "\n",
    "**Tip**: After each task, I recommend that you check the shape and the contents of your objects, to confirm that they match your expectations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/caboe/Dropbox/DataSchool/Untitled Folder\n"
     ]
    }
   ],
   "source": [
    "# Verify in the correct directory\n",
    "import os\n",
    "print os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import the data from the github repo\n",
    "# This requires importing pandas\n",
    "import pandas as pd\n",
    "URL = 'https://raw.githubusercontent.com/dataschool/MLtext2/master/data/yelp.csv?token=AEv2W1BCiQQ1BDnLNLKueYQk6kBwkfb4ks5XFCmAwA%3D%3D'\n",
    "posts = pd.read_csv(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These URLs worked in a pinch when I couldn't access the private repos\n",
    "# posts = pd.read_csv('https://github.com/dataschool/MLtext2/blob/master/data/yelp.csv?raw=true')\n",
    "#url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/sms.tsv'\n",
    "#sms = pd.read_table(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the DF\n",
    "posts.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>VY_tvNUCCXGXQeSvJl757Q</td>\n",
       "      <td>2012-07-28</td>\n",
       "      <td>Ubyfp2RSDYW0g7Mbr8N3iA</td>\n",
       "      <td>3</td>\n",
       "      <td>First visit...Had lunch here today - used my G...</td>\n",
       "      <td>review</td>\n",
       "      <td>_eqQoPtQ3e3UxLE4faT6ow</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>EKzMHI1tip8rC1-ZAy64yg</td>\n",
       "      <td>2012-01-18</td>\n",
       "      <td>2XyIOQKbVFb6uXQdJ0RzlQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Should be called house of deliciousness!\\n\\nI ...</td>\n",
       "      <td>review</td>\n",
       "      <td>ROru4uk5SaYc3rg8IU7SQw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>53YGfwmbW73JhFiemNeyzQ</td>\n",
       "      <td>2010-11-16</td>\n",
       "      <td>jyznYkIbpqVmlsZxSDSypA</td>\n",
       "      <td>4</td>\n",
       "      <td>I recently visited Olive and Ivy for business ...</td>\n",
       "      <td>review</td>\n",
       "      <td>gGbN1aKQHMgfQZkqlsuwzg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9SKdOoDHcFoxK5ZtsgHJoA</td>\n",
       "      <td>2012-12-02</td>\n",
       "      <td>5UKq9WQE1qQbJ0DJbc-B6Q</td>\n",
       "      <td>2</td>\n",
       "      <td>My nephew just moved to Scottsdale recently so...</td>\n",
       "      <td>review</td>\n",
       "      <td>0lyVoNazXa20WzUyZPLaQQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>pF7uRzygyZsltbmVpjIyvw</td>\n",
       "      <td>2010-10-16</td>\n",
       "      <td>vWSmOhg2ID1MNZHaWapGbA</td>\n",
       "      <td>5</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>review</td>\n",
       "      <td>KSBFytcdjPKZgXKQnYQdkA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id        date               review_id  stars  \\\n",
       "9995  VY_tvNUCCXGXQeSvJl757Q  2012-07-28  Ubyfp2RSDYW0g7Mbr8N3iA      3   \n",
       "9996  EKzMHI1tip8rC1-ZAy64yg  2012-01-18  2XyIOQKbVFb6uXQdJ0RzlQ      4   \n",
       "9997  53YGfwmbW73JhFiemNeyzQ  2010-11-16  jyznYkIbpqVmlsZxSDSypA      4   \n",
       "9998  9SKdOoDHcFoxK5ZtsgHJoA  2012-12-02  5UKq9WQE1qQbJ0DJbc-B6Q      2   \n",
       "9999  pF7uRzygyZsltbmVpjIyvw  2010-10-16  vWSmOhg2ID1MNZHaWapGbA      5   \n",
       "\n",
       "                                                   text    type  \\\n",
       "9995  First visit...Had lunch here today - used my G...  review   \n",
       "9996  Should be called house of deliciousness!\\n\\nI ...  review   \n",
       "9997  I recently visited Olive and Ivy for business ...  review   \n",
       "9998  My nephew just moved to Scottsdale recently so...  review   \n",
       "9999  4-5 locations.. all 4.5 star average.. I think...  review   \n",
       "\n",
       "                     user_id  cool  useful  funny  \n",
       "9995  _eqQoPtQ3e3UxLE4faT6ow     1       2      0  \n",
       "9996  ROru4uk5SaYc3rg8IU7SQw     0       0      0  \n",
       "9997  gGbN1aKQHMgfQZkqlsuwzg     0       0      0  \n",
       "9998  0lyVoNazXa20WzUyZPLaQQ     0       0      0  \n",
       "9999  KSBFytcdjPKZgXKQnYQdkA     0       0      0  "
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the last few rows in the df\n",
    "posts.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    3526\n",
       "5    3337\n",
       "3    1461\n",
       "2     927\n",
       "1     749\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the value counts on the classes we will be predicting with our model\n",
    "posts.stars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(posts.stars.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    3526\n",
       "5    3337\n",
       "3    1461\n",
       "2     927\n",
       "1     749\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.stars.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      "business_id    10000 non-null object\n",
      "date           10000 non-null object\n",
      "review_id      10000 non-null object\n",
      "stars          10000 non-null int64\n",
      "text           10000 non-null object\n",
      "type           10000 non-null object\n",
      "user_id        10000 non-null object\n",
      "cool           10000 non-null int64\n",
      "useful         10000 non-null int64\n",
      "funny          10000 non-null int64\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 781.3+ KB\n"
     ]
    }
   ],
   "source": [
    "posts.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Task 2: Create a new DataFrame that only contains the 5-star and 1-star reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a dataframe with only 1 and 5 star reviews.\n",
    "fives_ones = posts[(posts['stars'] > 4) |(posts['stars'] < 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4086, 10)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the shape of the new daatframe\n",
    "fives_ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zp713qNhx8d9KCJJnrw1xA</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>riFQ3vxNpP4rWLk_CSri2A</td>\n",
       "      <td>5</td>\n",
       "      <td>Drop what you're doing and drive here. After I...</td>\n",
       "      <td>review</td>\n",
       "      <td>wFweIWhv2fREZV_dYkz_1g</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "6  zp713qNhx8d9KCJJnrw1xA  2010-02-12  riFQ3vxNpP4rWLk_CSri2A      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "6  Drop what you're doing and drive here. After I...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  \n",
       "6  wFweIWhv2fREZV_dYkz_1g     7       7      4  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at head\n",
    "fives_ones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>R8VwdLyvsp9iybNqRvm94g</td>\n",
       "      <td>2011-10-03</td>\n",
       "      <td>pcEeHdAJPoFNF23es0kKWg</td>\n",
       "      <td>5</td>\n",
       "      <td>Yes I do rock the hipster joints.  I dig this ...</td>\n",
       "      <td>review</td>\n",
       "      <td>b92Y3tyWTQQZ5FLifex62Q</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>WJ5mq4EiWYAA4Vif0xDfdg</td>\n",
       "      <td>2011-12-05</td>\n",
       "      <td>EuHX-39FR7tyyG1ElvN1Jw</td>\n",
       "      <td>5</td>\n",
       "      <td>Only 4 stars? \\n\\n(A few notes: The folks that...</td>\n",
       "      <td>review</td>\n",
       "      <td>hTau-iNZFwoNsPCaiIUTEA</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>f96lWMIAUhYIYy9gOktivQ</td>\n",
       "      <td>2009-03-10</td>\n",
       "      <td>YF17z7HWlMj6aezZc-pVEw</td>\n",
       "      <td>5</td>\n",
       "      <td>I'm not normally one to jump at reviewing a ch...</td>\n",
       "      <td>review</td>\n",
       "      <td>W_QXYA7A0IhMrvbckz7eVg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>L3BSpFvxcNf3T_teitgt6A</td>\n",
       "      <td>2012-03-19</td>\n",
       "      <td>0nxb1gIGFgk3WbC5zwhKZg</td>\n",
       "      <td>5</td>\n",
       "      <td>Let's see...what is there NOT to like about Su...</td>\n",
       "      <td>review</td>\n",
       "      <td>OzOZv-Knlw3oz9K5Kh5S6A</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>pF7uRzygyZsltbmVpjIyvw</td>\n",
       "      <td>2010-10-16</td>\n",
       "      <td>vWSmOhg2ID1MNZHaWapGbA</td>\n",
       "      <td>5</td>\n",
       "      <td>4-5 locations.. all 4.5 star average.. I think...</td>\n",
       "      <td>review</td>\n",
       "      <td>KSBFytcdjPKZgXKQnYQdkA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 business_id        date               review_id  stars  \\\n",
       "9990  R8VwdLyvsp9iybNqRvm94g  2011-10-03  pcEeHdAJPoFNF23es0kKWg      5   \n",
       "9991  WJ5mq4EiWYAA4Vif0xDfdg  2011-12-05  EuHX-39FR7tyyG1ElvN1Jw      5   \n",
       "9992  f96lWMIAUhYIYy9gOktivQ  2009-03-10  YF17z7HWlMj6aezZc-pVEw      5   \n",
       "9994  L3BSpFvxcNf3T_teitgt6A  2012-03-19  0nxb1gIGFgk3WbC5zwhKZg      5   \n",
       "9999  pF7uRzygyZsltbmVpjIyvw  2010-10-16  vWSmOhg2ID1MNZHaWapGbA      5   \n",
       "\n",
       "                                                   text    type  \\\n",
       "9990  Yes I do rock the hipster joints.  I dig this ...  review   \n",
       "9991  Only 4 stars? \\n\\n(A few notes: The folks that...  review   \n",
       "9992  I'm not normally one to jump at reviewing a ch...  review   \n",
       "9994  Let's see...what is there NOT to like about Su...  review   \n",
       "9999  4-5 locations.. all 4.5 star average.. I think...  review   \n",
       "\n",
       "                     user_id  cool  useful  funny  \n",
       "9990  b92Y3tyWTQQZ5FLifex62Q     1       1      1  \n",
       "9991  hTau-iNZFwoNsPCaiIUTEA     1       1      0  \n",
       "9992  W_QXYA7A0IhMrvbckz7eVg     2       3      2  \n",
       "9994  OzOZv-Knlw3oz9K5Kh5S6A     1       2      1  \n",
       "9999  KSBFytcdjPKZgXKQnYQdkA     0       0      0  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at tail\n",
    "fives_ones.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    3337\n",
       "1     749\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the value counts to make sure only contains 5 and 1 classes\n",
    "fives_ones.stars.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Task 3\n",
    "Define X and y from the new DataFrame, and then split X and y into training and testing sets, using the review text as the only feature and the star rating as the response.\n",
    "\n",
    "- Hint: Keep in mind that X should be a Pandas Series (not a DataFrame), since we will pass it to CountVectorizer in the task that follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create X feature series of text reviews ONLY\n",
    "# create y response series of star ratings\n",
    "X = fives_ones.text \n",
    "y= fives_ones.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# splite these two Series into train and test splits\n",
    "# use the sklearn cross validation package train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (3064,)\n",
      "y_train (3064,)\n",
      "\n",
      "X_test (1022,)\n",
      "y_test (1022,)\n"
     ]
    }
   ],
   "source": [
    "# Check the shape of each of the new train and test splits\n",
    "print \"X_train\", X_train.shape \n",
    "print \"y_train\", y_train.shape\n",
    "print\n",
    "print \"X_test\", X_test.shape\n",
    "print \"y_test\", y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    My wife took me here on my birthday for breakf...\n",
       "1    I have no idea why some people give bad review...\n",
       "3    Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
       "4    General Manager Scott Petello is a good egg!!!...\n",
       "6    Drop what you're doing and drive here. After I...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    5\n",
       "3    5\n",
       "4    5\n",
       "6    5\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Use CountVectorizer to create document-term matrices from X_train and X_test.\n",
    "- CountVectorizer is a feature extraction tool in SKL \n",
    "- CountVectorizer converts a collection of text documents into a matrix of token counts\n",
    "- Each document (ie, observation) passed to the CountVectorizer algorithm will be parsed and each word will be converted to a matrix where each word is a feature in that matrix along with a count of the number of times that word appeared in the document.\n",
    "- The result is a sparse feature matrix\n",
    "- This process is known as vectorization (as well as a tokenization) and results in what is commonly referred to as a bag of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the CountVectorizer\n",
    "# instantiate the CountVectorizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vect = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The CountVecorizer instance learns the X training data vocabulary\n",
    "vect.fit(X_train)\n",
    "\n",
    "# This learned vocabular is then used to create the document term matrix\n",
    "# This docment term matrix (dtm) is the sparse matrix where each word is a feature\n",
    "# And each row contains the count of that word contained in that observations document.\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "\n",
    "#NB: These steps can be combined\n",
    "#X_train_dtm = vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 136)\t1\n",
      "  (0, 805)\t4\n",
      "  (0, 1003)\t1\n",
      "  (0, 1018)\t1\n",
      "  (0, 1528)\t1\n",
      "  (0, 1564)\t1\n",
      "  (0, 1902)\t1\n",
      "  (0, 2069)\t1\n",
      "  (0, 2285)\t1\n",
      "  (0, 2286)\t2\n",
      "  (0, 2398)\t1\n",
      "  (0, 2789)\t1\n",
      "  (0, 3213)\t1\n",
      "  (0, 3233)\t1\n",
      "  (0, 3679)\t1\n",
      "  (0, 3999)\t1\n",
      "  (0, 4631)\t1\n",
      "  (0, 4809)\t1\n",
      "  (0, 4837)\t1\n",
      "  (0, 5342)\t2\n",
      "  (0, 5773)\t1\n",
      "  (0, 5882)\t1\n",
      "  (0, 6028)\t1\n",
      "  (0, 6154)\t1\n",
      "  (0, 6433)\t1\n",
      "  :\t:\n",
      "  (3063, 6974)\t1\n",
      "  (3063, 7023)\t1\n",
      "  (3063, 7181)\t1\n",
      "  (3063, 8189)\t2\n",
      "  (3063, 9318)\t1\n",
      "  (3063, 9438)\t1\n",
      "  (3063, 9440)\t1\n",
      "  (3063, 9807)\t1\n",
      "  (3063, 10352)\t2\n",
      "  (3063, 10805)\t1\n",
      "  (3063, 12038)\t1\n",
      "  (3063, 14137)\t1\n",
      "  (3063, 14720)\t1\n",
      "  (3063, 14836)\t1\n",
      "  (3063, 14994)\t1\n",
      "  (3063, 15032)\t2\n",
      "  (3063, 15042)\t1\n",
      "  (3063, 15093)\t2\n",
      "  (3063, 15228)\t1\n",
      "  (3063, 15281)\t1\n",
      "  (3063, 15834)\t1\n",
      "  (3063, 15968)\t1\n",
      "  (3063, 16162)\t1\n",
      "  (3063, 16252)\t2\n",
      "  (3063, 16599)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<3064x16825 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 237720 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the document term matrix\n",
    "print X_train_dtm\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform the testing data, using the fitted vocab in vect\n",
    "# the result is that any new words in the X_test set will be ignored\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1022x16825 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 77006 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the X_test_dtm document term matrix\n",
    "X_test_dtm\n",
    "\n",
    "#Notice that it has the same number of unique words (features) as the X_train  dat set\n",
    "# However it still has the same number of observations as X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
      "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
      "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n"
     ]
    }
   ],
   "source": [
    "print vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Task 5\n",
    "- Use Multinomial Naive Bayes to predict the star rating for the reviews in the testing set, and then calculate the accuracy and print the confusion matrix.\n",
    "- Hint: Evaluating a classification model explains how to interpret both classification accuracy and the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the Multinomial NB classifier from SKL\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# instantiate the Multi NB classifier\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.92 ms, sys: 2.03 ms, total: 8.95 ms\n",
      "Wall time: 8.02 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using the X_train_dtm (and time with %time magic function)\n",
    "%time nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make class predictions on the reviews based on the X_test_dtm\n",
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91878669275929548"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the accuracy of the class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[126,  58],\n",
       "       [ 25, 813]])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the confusion matrix\n",
    "metrics.confusion_matrix(y_test,y_pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+00,   9.99759874e-01,   1.00000000e+00, ...,\n",
       "         1.00000000e+00,   1.05200807e-19,   9.99915316e-01])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# putll out the associated predicted probability of each review\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:,1]\n",
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Task 6 (Challenge)\n",
    "Calculate the null accuracy, which is the classification accuracy that could be achieved by always predicting the most frequent class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    838\n",
       "1    184\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class distributions \n",
    "y_test.value_counts()\n",
    "\n",
    "# Null Accuracy would be simply always choosing 5 as the response value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate the percentages of each class\n",
    "fives = y_test.value_counts()[5]\n",
    "ones = y_test.value_counts()[1]\n",
    "total = fives + ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null accuracy null_acc is 0.819960861057\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percent of y_test responses that are 5 stars\n",
    "five_acc = float(fives)/total\n",
    "one_acc = float(ones)/total\n",
    "print \"Null accuracy null_acc is\", max(five_acc, one_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Task 7 (Challenge)\n",
    "Browse through the review text of some of the false positives and false negatives. Based on your knowledge of how Naive Bayes works, do you have any ideas about why the model is incorrectly classifying these reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# False Positive (FP): an actual one star review was predicted as a five star review, \n",
    "# ie y_test < y_pred_class\n",
    "# False Negative (FN): an acutal five star review was predicted as a one star review, \n",
    "# ie y_test > y_pred_class\n",
    "\n",
    "FP = y_test < y_pred_class\n",
    "FN = y_test > y_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variables containing those reviews that are FN and FP respectively to examine a few\n",
    "FP_reviews = X_test[FP]\n",
    "FN_reviews = X_test[FN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2175    This has to be the worst restaurant in terms o...\n",
       "1781    If you like the stuck up Scottsdale vibe this ...\n",
       "2674    I'm sorry to be what seems to be the lone one ...\n",
       "9984    Went last night to Whore Foods to get basics t...\n",
       "3392    I found Lisa G's while driving through phoenix...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the head of the FP reviews to check out which review ids to look at.\n",
    "FP_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I found Lisa G's while driving through phoenix with a friend. The exterior looked promising and we prepared ourselves for a treat. We were in for a a shock! We ordered the antipasto plate and while there were serious issues with it, it turned out to be the best thing we were served. I ordered the chicken rolatini (the special of the day) and it was just plain bad! The chicken was dry and under seasoned, the Rosemary potatoes were soggy  and the veggie medley  (squash, corn, green beans, etc.) was over cooked and the juices spilled over into the potatoes. It was one of the worst $17 meals that I have ever had! My friend ordered the veggie salad and it was one literal hot mess. Just horrible food! I see that others had the mini burgers and bowl of balls and found them to be tasty. I wish I had ordered those. As it is this is one place I would never revisit or recommend to a friend!\""
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review a few of these False Positives \n",
    "FP_reviews[2175]\n",
    "FP_reviews[1781]\n",
    "FP_reviews[2674]\n",
    "FP_reviews[9984]\n",
    "FP_reviews[3392]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7148    I now consider myself an Arizonian. If you dri...\n",
       "4963    This is by far my favourite department store, ...\n",
       "6318    Since I have ranted recently on poor customer ...\n",
       "380     This is a must try for any Mani Pedi fan. I us...\n",
       "5565    I`ve had work done by this shop a few times th...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the head of the False Negative Reviews\n",
    "FN_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is by far my favourite department store, hands down. I have had nothing but perfect experiences in this store, without exception, no matter what department I\\'m in. The shoe SA\\'s will bend over backwards to help you find a specific shoe, and the staff will even go so far as to send out hand-written thank you cards to your home address after you make a purchase - big or small. Tim & Anthony in the shoe salon are fabulous beyond words! \\n\\nI am not completely sure that I understand why people complain about the amount of merchandise on the floor or the lack of crowds in this store. Frankly, I would rather not be bombarded with merchandise and other people. One of the things I love the most about Barney\\'s is not only the prompt attention of SA\\'s, but the fact that they aren\\'t rushing around trying to help 35 people at once. The SA\\'s at Barney\\'s are incredibly friendly and will stop to have an actual conversation, regardless or whether you are purchasing something or not. I have also never experienced a \"high pressure\" sale situation here.\\n\\nAll in all, Barneys is pricey, and there is no getting around it. But, um, so is Neiman\\'s and that place is a crock. Anywhere that ONLY accepts American Express or their charge card and then treats you like scum if you aren\\'t carrying neither is no place that I want to spend my hard earned dollars. Yay Barneys!'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the content of a handful of FN reviews to better understand their misclassification\n",
    "FN_reviews[7148]\n",
    "FN_reviews[4963]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on your knowledge of how Naive Bayes works, do you have any ideas about why the model is incorrectly classifying these reviews?\n",
    "**The model is incorrectly classifying these FP and FN reviews because of the simplicity of the classifier which only looks at unique  words and their respective counts when determining likely association with a given response class.  This results in broader context and subtlety of speech being misinterpreted by the classifier - for instance with sarcasm or negation as well as ambiguity with words that have multiple meanings in a language.** \n",
    "- For example, **the classifier cannot incorporate the impact of negation**: The phrase, *\"I don't like this place\"* could be seen as a positive review by the classifier because it will count the 1-gram \"like\" as contributing to the increased likilehood this a positive review.  \n",
    "- Additionally with **word ambiguity**:  A review that uses the word \"like\" as a preposition to mean \"similiar to\" (ie, *\"the bun tasted like liver.\"*) will count the presence of the word \"like\" towards an increased likelihood this is a positive review because the classifier has learned that \"like\" is most often present in positive reviews which employ \"like\" as a verb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##Task 8 (Challenge)\n",
    "Calculate which 10 tokens are the most predictive of 5-star reviews, and which 10 tokens are the most predictive of 1-star reviews.\n",
    "Hint: Naive Bayes automatically counts the number of times each token appears in each class, as well as the number of observations in each class. You can access these counts via the feature_count_ and class_count_ attributes of the Naive Bayes model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16825"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the vocabulary of X_train and review the number of tokens\n",
    "X_train_tokens = vect.get_feature_names()\n",
    "len(X_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'absoloutely', u'absolut', u'absolute', u'absolutely', u'absolutley', u'absolutly', u'abstained', u'absurd', u'abuelo', u'abundance', u'abundant', u'abuse', u'abused', u'abusive', u'ac', u'academy', u'acapulco', u'accent', u'accented', u'accents', u'accept', u'acceptable', u'accepted', u'access', u'accessed', u'accessible', u'accessories', u'accessorize', u'accessory', u'accident', u'accidental', u'accidentally', u'accolades', u'accommodate', u'accommodated', u'accommodates', u'accommodating', u'accommodations', u'accomodate', u'accomodating', u'accompanied', u'accompanies', u'accompaniment', u'accompany', u'accompanying', u'accomplish', u'accomplished', u'accomplishment', u'according', u'accordingly']\n"
     ]
    }
   ],
   "source": [
    "# Examine a few of the first tokens\n",
    "print X_train_tokens[350:400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'yyyyy', u'z11', u'za', u'zabba', u'zach', u'zam', u'zanella', u'zankou', u'zappos', u'zatsiki', u'zen', u'zero', u'zest', u'zexperience', u'zha', u'zhou', u'zia', u'zihuatenejo', u'zilch', u'zin', u'zinburger', u'zinburgergeist', u'zinc', u'zinfandel', u'zing', u'zip', u'zipcar', u'zipper', u'zippers', u'zipps', u'ziti', u'zoe', u'zombi', u'zombies', u'zone', u'zones', u'zoning', u'zoo', u'zoyo', u'zucca', u'zucchini', u'zuchinni', u'zumba', u'zupa', u'zuzu', u'zwiebel', u'zzed', u'\\xe9clairs', u'\\xe9cole', u'\\xe9m']\n"
     ]
    }
   ],
   "source": [
    "# Examine the last 50 tokens\n",
    "print X_train_tokens[-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 26.,   4.,   1., ...,   0.,   0.,   0.],\n",
       "       [ 39.,   5.,   0., ...,   1.,   1.,   1.]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the number of times each token appears in each class\n",
    "nb.feature_count_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One tokens: [ 26.   4.   1. ...,   0.   0.   0.]\n",
      "Five tokens: [ 39.   5.   0. ...,   1.   1.   1.]\n"
     ]
    }
   ],
   "source": [
    "# grab the number of times each token appears across all reviews in the X_Train dataset\n",
    "one_token_count = nb.feature_count_[0, :]\n",
    "five_token_count = nb.feature_count_[1, :]\n",
    "print \"One tokens:\", one_token_count\n",
    "print \"Five tokens:\", five_token_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a DataFrame of the raw token counts separated with columns for one and five stars\n",
    "tokens = pd.DataFrame({\"token\":X_train_tokens,\"one\": one_token_count, \"five\":five_token_count}).set_index('token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five</th>\n",
       "      <th>one</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>puree</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rama</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helps</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forgotten</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>farther</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           five  one\n",
       "token               \n",
       "puree       5.0  0.0\n",
       "rama        1.0  0.0\n",
       "helps       8.0  1.0\n",
       "forgotten  10.0  2.0\n",
       "farther     1.0  0.0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine random tokens to see counts of each by class\n",
    "tokens.sample(5, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add 1 and normalize counts of each token to determine 10 most predictive tokens for one star reviews and \n",
    "# Five star reviews respectively\n",
    "tokens['five'] = tokens.five + 1\n",
    "tokens['one'] = tokens.one + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five</th>\n",
       "      <th>one</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>puree</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rama</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helps</th>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forgotten</th>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>farther</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           five  one\n",
       "token               \n",
       "puree       6.0  1.0\n",
       "rama        2.0  1.0\n",
       "helps       9.0  2.0\n",
       "forgotten  11.0  3.0\n",
       "farther     2.0  1.0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.sample(5,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Count: 565\n",
      "Five Count: 2499\n"
     ]
    }
   ],
   "source": [
    "# Check the count of each class\n",
    "print \"One Count:\", int(nb.class_count_[0])\n",
    "print \"Five Count:\", int(nb.class_count_[1])\n",
    "#print \"5 Star Count:\", len(y_train[y_train == 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert the five and one star token counts into frequencies\n",
    "# NB: Only run this cell once or the count per token will be divided by its class count each time\n",
    "tokens['one'] = tokens.one / nb.class_count_[0]\n",
    "tokens['five'] = tokens.five / nb.class_count_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five</th>\n",
       "      <th>one</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>puree</th>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.00177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rama</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.00177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helps</th>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.00354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forgotten</th>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.00531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>farther</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.00177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               five      one\n",
       "token                       \n",
       "puree      0.002401  0.00177\n",
       "rama       0.000800  0.00177\n",
       "helps      0.003601  0.00354\n",
       "forgotten  0.004402  0.00531\n",
       "farther    0.000800  0.00177"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the class frequency of each token\n",
    "tokens.sample(5,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the ratio of one-to-five star reviews for each token\n",
    "tokens['one_star_ratio'] = tokens.one/tokens.five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five</th>\n",
       "      <th>one</th>\n",
       "      <th>one_star_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>puree</th>\n",
       "      <td>0.002401</td>\n",
       "      <td>0.00177</td>\n",
       "      <td>0.737168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rama</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.00177</td>\n",
       "      <td>2.211504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>helps</th>\n",
       "      <td>0.003601</td>\n",
       "      <td>0.00354</td>\n",
       "      <td>0.982891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>forgotten</th>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.00531</td>\n",
       "      <td>1.206275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>farther</th>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.00177</td>\n",
       "      <td>2.211504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               five      one  one_star_ratio\n",
       "token                                       \n",
       "puree      0.002401  0.00177        0.737168\n",
       "rama       0.000800  0.00177        2.211504\n",
       "helps      0.003601  0.00354        0.982891\n",
       "forgotten  0.004402  0.00531        1.206275\n",
       "farther    0.000800  0.00177        2.211504"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Review the likelihood each token is associated with a 1 star review\n",
    "tokens.sample(5,random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 tokens most predicitve of 1-star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five</th>\n",
       "      <th>one</th>\n",
       "      <th>one_star_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>staffperson</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.030088</td>\n",
       "      <td>75.191150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>refused</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.024779</td>\n",
       "      <td>61.922124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>disgusting</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.042478</td>\n",
       "      <td>53.076106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filthy</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.019469</td>\n",
       "      <td>48.653097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unacceptable</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>39.807080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acknowledge</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>39.807080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unprofessional</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.015929</td>\n",
       "      <td>39.807080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ugh</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.030088</td>\n",
       "      <td>37.595575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yuck</th>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.028319</td>\n",
       "      <td>35.384071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fuse</th>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>35.384071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  five       one  one_star_ratio\n",
       "token                                           \n",
       "staffperson     0.0004  0.030088       75.191150\n",
       "refused         0.0004  0.024779       61.922124\n",
       "disgusting      0.0008  0.042478       53.076106\n",
       "filthy          0.0004  0.019469       48.653097\n",
       "unacceptable    0.0004  0.015929       39.807080\n",
       "acknowledge     0.0004  0.015929       39.807080\n",
       "unprofessional  0.0004  0.015929       39.807080\n",
       "ugh             0.0008  0.030088       37.595575\n",
       "yuck            0.0008  0.028319       35.384071\n",
       "fuse            0.0004  0.014159       35.384071"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the DF sorted by one_star_ratio\n",
    "# Sort in descending order to find the top 10 tokens most predictive of 1-star reviews\n",
    "tokens.sort_values('one_star_ratio',ascending = False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 tokens most predicitve of 5-star reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>five</th>\n",
       "      <th>one</th>\n",
       "      <th>one_star_ratio</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fantastic</th>\n",
       "      <td>0.077231</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.045834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perfect</th>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.054159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yum</th>\n",
       "      <td>0.024810</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.071339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>favorite</th>\n",
       "      <td>0.138055</td>\n",
       "      <td>0.012389</td>\n",
       "      <td>0.089742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outstanding</th>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.090265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brunch</th>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.105310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gem</th>\n",
       "      <td>0.016006</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.110575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mozzarella</th>\n",
       "      <td>0.015606</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.113410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pasty</th>\n",
       "      <td>0.015606</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>0.113410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amazing</th>\n",
       "      <td>0.185274</td>\n",
       "      <td>0.021239</td>\n",
       "      <td>0.114635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 five       one  one_star_ratio\n",
       "token                                          \n",
       "fantastic    0.077231  0.003540        0.045834\n",
       "perfect      0.098039  0.005310        0.054159\n",
       "yum          0.024810  0.001770        0.071339\n",
       "favorite     0.138055  0.012389        0.089742\n",
       "outstanding  0.019608  0.001770        0.090265\n",
       "brunch       0.016807  0.001770        0.105310\n",
       "gem          0.016006  0.001770        0.110575\n",
       "mozzarella   0.015606  0.001770        0.113410\n",
       "pasty        0.015606  0.001770        0.113410\n",
       "amazing      0.185274  0.021239        0.114635"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the DF sorted by one_star_ratio\n",
    "# Sort in descending order to find the top 10 tokens most predictive of 1-star reviews\n",
    "tokens.sort_values('one_star_ratio').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###Task 9 (Challenge)\n",
    "Up to this point, we have framed this as a binary classification problem by only considering the 5-star and 1-star reviews. Now, let's repeat the model building process using all reviews, which makes this a 5-class classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "# Create X feature matrix and y response series using all observations in the dataset\n",
    "X_all = posts.text\n",
    "y_all = posts.stars\n",
    "print X_all.shape\n",
    "print y_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500,)\n",
      "(2500,)\n",
      "(7500,)\n",
      "(2500,)\n"
     ]
    }
   ],
   "source": [
    "# Create train_test split\n",
    "X_all_train, X_all_test, y_all_train, y_all_test = train_test_split(X_all, y_all, random_state = 1)\n",
    "print X_all_train.shape\n",
    "print X_all_test.shape\n",
    "print y_all_train.shape\n",
    "print y_all_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 10754)\t1\n",
      "  (0, 13443)\t1\n",
      "  (0, 11649)\t2\n",
      "  (0, 4401)\t1\n",
      "  (0, 9216)\t3\n",
      "  (0, 14935)\t2\n",
      "  (0, 15765)\t2\n",
      "  (0, 15116)\t2\n",
      "  (0, 13287)\t1\n",
      "  (0, 24893)\t1\n",
      "  (0, 14895)\t1\n",
      "  (0, 23005)\t1\n",
      "  (0, 15333)\t1\n",
      "  (0, 25080)\t1\n",
      "  (0, 1238)\t1\n",
      "  (0, 1577)\t1\n",
      "  (0, 17145)\t3\n",
      "  (0, 8353)\t1\n",
      "  (0, 25428)\t1\n",
      "  (0, 2332)\t1\n",
      "  (0, 13321)\t1\n",
      "  (0, 23029)\t3\n",
      "  (0, 16507)\t1\n",
      "  (0, 1741)\t1\n",
      "  (0, 25045)\t1\n",
      "  :\t:\n",
      "  (7499, 7245)\t1\n",
      "  (7499, 23814)\t1\n",
      "  (7499, 13104)\t1\n",
      "  (7499, 20132)\t1\n",
      "  (7499, 18560)\t1\n",
      "  (7499, 22453)\t1\n",
      "  (7499, 10075)\t1\n",
      "  (7499, 11774)\t1\n",
      "  (7499, 11271)\t1\n",
      "  (7499, 21208)\t1\n",
      "  (7499, 22200)\t1\n",
      "  (7499, 12313)\t1\n",
      "  (7499, 9250)\t1\n",
      "  (7499, 11559)\t1\n",
      "  (7499, 3474)\t1\n",
      "  (7499, 21048)\t1\n",
      "  (7499, 18639)\t1\n",
      "  (7499, 19493)\t1\n",
      "  (7499, 5465)\t1\n",
      "  (7499, 12693)\t1\n",
      "  (7499, 1849)\t1\n",
      "  (7499, 22367)\t1\n",
      "  (7499, 23648)\t1\n",
      "  (7499, 4890)\t1\n",
      "  (7499, 123)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<7500x25797 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 622700 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate the CV\n",
    "vect_all = CountVectorizer()\n",
    "# fit_transform the vect_all CV and create DTMs\n",
    "X_train_all_dtm = vect_all.fit_transform(X_all_train)\n",
    "X_test_all_dtm = vect_all.transform(X_all_test)\n",
    "\n",
    "# print details X_train_all_dtm\n",
    "print X_train_all_dtm\n",
    "X_train_all_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1262)\t1\n",
      "  (0, 1829)\t1\n",
      "  (0, 2020)\t1\n",
      "  (0, 2046)\t1\n",
      "  (0, 2246)\t1\n",
      "  (0, 2332)\t1\n",
      "  (0, 3578)\t1\n",
      "  (0, 5904)\t1\n",
      "  (0, 6879)\t1\n",
      "  (0, 8760)\t1\n",
      "  (0, 9942)\t1\n",
      "  (0, 10052)\t1\n",
      "  (0, 10249)\t1\n",
      "  (0, 11047)\t1\n",
      "  (0, 11062)\t1\n",
      "  (0, 11649)\t1\n",
      "  (0, 12187)\t1\n",
      "  (0, 12540)\t1\n",
      "  (0, 13612)\t1\n",
      "  (0, 13982)\t1\n",
      "  (0, 14379)\t1\n",
      "  (0, 15415)\t1\n",
      "  (0, 15565)\t1\n",
      "  (0, 15765)\t1\n",
      "  (0, 15832)\t1\n",
      "  :\t:\n",
      "  (2499, 23029)\t24\n",
      "  (2499, 23058)\t1\n",
      "  (2499, 23072)\t2\n",
      "  (2499, 23089)\t1\n",
      "  (2499, 23112)\t1\n",
      "  (2499, 23317)\t5\n",
      "  (2499, 23380)\t5\n",
      "  (2499, 23390)\t1\n",
      "  (2499, 23509)\t1\n",
      "  (2499, 23684)\t1\n",
      "  (2499, 23758)\t1\n",
      "  (2499, 23759)\t1\n",
      "  (2499, 23760)\t1\n",
      "  (2499, 24359)\t1\n",
      "  (2499, 24480)\t1\n",
      "  (2499, 24573)\t3\n",
      "  (2499, 24827)\t2\n",
      "  (2499, 24852)\t1\n",
      "  (2499, 24893)\t4\n",
      "  (2499, 25309)\t2\n",
      "  (2499, 25314)\t1\n",
      "  (2499, 25405)\t1\n",
      "  (2499, 25428)\t1\n",
      "  (2499, 25641)\t3\n",
      "  (2499, 25653)\t3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2500x25797 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 200729 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print details about X_test_all_dtm\n",
    "print X_test_all_dtm\n",
    "X_test_all_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run Multinomial NB classifier to create model and make predictions\n",
    "#instantiate\n",
    "nb_all = MultinomialNB()\n",
    "# fit\n",
    "nb.fit(X_train_all_dtm, y_all_train)\n",
    "# predict\n",
    "y_pred_all = nb.predict(X_test_all_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47120000000000001"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine accuracy of the predicted values\n",
    "# import the metrics module from SKL\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_all_test,y_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4    2642\n",
      "5    2505\n",
      "3    1096\n",
      "2     693\n",
      "1     564\n",
      "Name: stars, dtype: int64\n",
      "The null accuracy is 35.2% and is for class 4\n"
     ]
    }
   ],
   "source": [
    "# Calculate null accuracy\n",
    "# Determine raw counts of each \n",
    "print y_all_train.value_counts()\n",
    "\n",
    "# Convert raw counts to percentages and create dictionary of class:percent\n",
    "ratings = range(1,6)\n",
    "d = {x:((y_all_train.value_counts()[x])/(float(len(y_all_train)))) for x in ratings}\n",
    "null_acc = max(d.values())\n",
    "\n",
    "# Find the null accuracy and the associated class\n",
    "null_star = [k for k,v in d.iteritems() if v == null_acc]\n",
    "print \"The null accuracy is\", str(round(null_acc,3)*100) + \"% \" + \"and is for class\", null_star[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "4    884\n",
      "5    832\n",
      "3    365\n",
      "2    234\n",
      "1    185\n",
      "Name: stars, dtype: int64\n",
      "4    0.3536\n",
      "5    0.3328\n",
      "3    0.1460\n",
      "2    0.0936\n",
      "1    0.0740\n",
      "Name: stars, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Review the value_count class details about y_all_test \n",
    "print y_all_test.shape[0]\n",
    "print y_all_test.value_counts()\n",
    "print y_all_test.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 55,  14,  24,  65,  27],\n",
       "       [ 28,  16,  41, 122,  27],\n",
       "       [  5,   7,  35, 281,  37],\n",
       "       [  7,   0,  16, 629, 232],\n",
       "       [  6,   4,   6, 373, 443]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the confusion matrix\n",
    "metrics.confusion_matrix(y_all_test,y_pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Comment on the output of the confusion matrix\n",
    "Overall, the classifier demonstrates a classification accuracy of 47%, which, while not great, is 12 points better than the null accuracy of 35.2%.  In general, the model skews towards predicting a \"positive\" review, i.e. designating a review as either class 4 or class 5 - with a particular tendency to predict class 4.  For example, in this split, the model predicted 1470 class 4 responses out of a total of 2500 observations.  This represents ~ 59% of all reviews, despite the fact that class 4 responses only constitute about 35% of the actual observations.  In fact, class 4 is the most predicted class across actual classes, with the exception of class 5.  It is model's ability to accuartely predict class 4 (approx 70% accuracy) and class 5 (approx 50% accuracy) that adds the most predictive power to the model as compared to the null accuracy.  \n",
    "\n",
    "In contrast, with neutral (3 star) and \"negative\" (1 or 2 star) classes, the model does not have much predictive power.  In the cases of an actual class 1, the model does correctly predict 30% of observations (55 reviews) accurately despite only 7.5% of the test observations belonging to Class 1.  However, the model still incorrectly labels 65 actual Class 1 observatins as belonging to Class 4, which is still greater in raw terms than the 55 observations it correctly assigns to class 1. And the model is particularly poor at discerning Class 2 observations (16 total correct, or 6.8% accuracy) and Class 3 observations (35 total correct, or ~10% accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the Clasification Report from the SKL metrics module\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the Classification Report on the y_test and y_pred_prob classes\n",
    "class_report = classification_report(y_all_test, y_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.30      0.38       185\n",
      "          2       0.39      0.07      0.12       234\n",
      "          3       0.29      0.10      0.14       365\n",
      "          4       0.43      0.71      0.53       884\n",
      "          5       0.58      0.53      0.55       832\n",
      "\n",
      "avg / total       0.46      0.47      0.43      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the results of the clasification report\n",
    "print class_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on the Results of the Classification Report\n",
    "The model demonstrates an average precision across all classes of 46% along with an average recall of 47%.  Overall, the weighted average of these two scores results in the model having an f1-score, or an average accuracy, of 43%.  This is still better than the null accuracy that can be achieved by simply labeling all observations as class 4, but there are some areas where the model could be improved.  Particularly, the model's recall on Class 1, 2 and 3 is further evidence that this model is particually poor at predicting non-positive (ie, non Class 4 or 5) reviews, as noted in the confusion matrix analysis above.  Additionally, the model's high recall and low precision with Class 4 indicates the model's skewed tendency towards labeling a majority of observations as Class 4.  Based on these findings, I would suggest improving the model (perhaps by parameter tuning or the use of a larger datset) to better discern features that are specific to non-positive classes (Classes 1,2,3) and perhaps using the model to predict positive vs non-positive ratings instead."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
